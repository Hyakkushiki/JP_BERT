{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_JP_fine-tuning",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOY4QfCcyIMmciSzsXwYMzc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericodle/JP_BERT/blob/main/BERT_JP_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted method of fine-tuning a pre-trained Japanese BERT model from Chris McCormick's online tutorial (https://mccormickml.com/2019/07/22/BERT-fine-tuning/)."
      ],
      "metadata": {
        "id": "XTVN1NEVpc76"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d16c8b4-dd1c-4ddb-eafb-14fd1cf0617c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5300411e-4efe-45b0-ed0d-855479f4ba17"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7yWN2u1qXyI",
        "outputId": "5897d1e8-698c-4d3f-c68d-c709b72b20cc"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install fugashi\n",
        "!pip install ipadic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 46.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 509 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n",
            "Collecting fugashi\n",
            "  Downloading fugashi-1.1.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (490 kB)\n",
            "\u001b[K     |████████████████████████████████| 490 kB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: fugashi\n",
            "Successfully installed fugashi-1.1.1\n",
            "Collecting ipadic\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.4 MB 5.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ipadic\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556723 sha256=cfa92038a2538ffd4554f3ac7269d7848849238e5e4b7958745e176385ac4915\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/8b/99/cf0d27191876637cd3639a560f93aa982d7855ce826c94348b\n",
            "Successfully built ipadic\n",
            "Installing collected packages: ipadic\n",
            "Successfully installed ipadic-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "sQLujPgGqn18",
        "outputId": "40b23152-5c19-4db3-ab6c-d93a40f16910"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/training_testrun.csv\", delimiter=',', header=None, names=['sentence', 'label'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7d0792123b3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the dataset into a pandas dataframe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/training_testrun.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Report the number of sentences.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/training_testrun.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsdQ4fY7sSON"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO7Vs5FKsYiV"
      },
      "source": [
        "from transformers import BertJapaneseTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lbyy0Z5tAsN",
        "outputId": "66d52409-26ba-4fc3-c836-70d9fc9f0c5c"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  '現実に結果がともなわなくとも，というよりそうであればそうであるほど，松陰は，いっそう純粋にいっそう過激に，みずからの誠のいたらなさを責めたのである。'\n",
            "Tokenized:  [\"'\", '現実', 'に', '結果', 'が', 'とも', '##なわ', 'なく', 'とも', ',', 'と', 'いう', 'より', 'そう', 'で', 'あれ', 'ば', 'そう', 'で', 'ある', 'ほど', ',', '松', '##陰', 'は', ',', 'いっ', '##そう', '純粋', 'に', 'いっ', '##そう', '過激', 'に', ',', 'みず', '##から', 'の', '誠', 'の', 'い', 'たら', 'な', 'さ', 'を', '責め', 'た', 'の', 'で', 'ある', '。', \"'\"]\n",
            "Token IDs:  [1507, 4419, 7, 854, 14, 981, 1967, 332, 981, 228, 13, 625, 221, 1778, 12, 2787, 312, 1778, 12, 31, 1101, 228, 812, 29929, 9, 228, 1281, 8946, 8924, 7, 1281, 8946, 10096, 7, 228, 13821, 2266, 5, 5283, 5, 21, 3318, 18, 26, 11, 26731, 10, 5, 12, 31, 8, 1507]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxWlYW8gtLc0",
        "outputId": "e48dacd0-6cfe-452c-92c5-6c71e9d897e6"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41yD28-ytR4L",
        "outputId": "8e2be6d7-e3a5-44aa-93d4-a1bab047fad4"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  '現実に結果がともなわなくとも，というよりそうであればそうであるほど，松陰は，いっそう純粋にいっそう過激に，みずからの誠のいたらなさを責めたのである。'\n",
            "Token IDs: tensor([    2,  1507,  4419,     7,   854,    14,   981,  1967,   332,   981,\n",
            "          228,    13,   625,   221,  1778,    12,  2787,   312,  1778,    12,\n",
            "           31,  1101,   228,   812, 29929,     9,   228,  1281,  8946,  8924,\n",
            "            7,  1281,  8946, 10096,     7,   228, 13821,  2266,     5,  5283,\n",
            "            5,    21,  3318,    18,    26,    11, 26731,    10,     5,    12,\n",
            "           31,     8,  1507,     3,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfSIKECwtZ-L",
        "outputId": "287474b7-b7ee-4c73-aa01-fb31d827041a"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  144 training samples\n",
            "   16 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssZCDIjVtgY1"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiazX_8Wty7J",
        "outputId": "d090e607-919a-4f71-d1fc-1d8068bb5811"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"cl-tohoku/bert-base-japanese-whole-word-masking\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 22, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=22, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHN3hTkZuK4N",
        "outputId": "50cfe78f-a218-4c5c-dfa8-8caa71889472"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (32000, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                          (22, 768)\n",
            "classifier.bias                                                (22,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLbONNsNulTo"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkBZ-o5sueKX"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JkVs2ayutuF"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLj3gFlMux3c"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62e807e6-bfe0-41d2-b6a5-acaf1804823e"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 3.11\n",
            "  Training epoch took: 0:00:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.06\n",
            "  Validation Loss: 3.08\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 2.97\n",
            "  Training epoch took: 0:00:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.06\n",
            "  Validation Loss: 3.04\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 2.90\n",
            "  Training epoch took: 0:00:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.12\n",
            "  Validation Loss: 3.02\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 2.87\n",
            "  Training epoch took: 0:00:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.12\n",
            "  Validation Loss: 3.01\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:00:25 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cC-18w1fxkvH",
        "outputId": "98e0cbee-f8ef-4eb1-e85c-113077f2dbbc"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.11</td>\n",
              "      <td>3.08</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0:00:06</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.97</td>\n",
              "      <td>3.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0:00:06</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.90</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0:00:06</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.87</td>\n",
              "      <td>3.01</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0:00:06</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               3.11         3.08           0.06       0:00:06         0:00:00\n",
              "2               2.97         3.04           0.06       0:00:06         0:00:00\n",
              "3               2.90         3.02           0.12       0:00:06         0:00:00\n",
              "4               2.87         3.01           0.12       0:00:06         0:00:00"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "xvlzZL4Lx9dl",
        "outputId": "2eae60b7-fe97-4631-f16c-7e72d4e336b0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EwlhREe0Xia"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4db625f-b675-42ca-eb98-80b661a9e42b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/trial_test.csv\", delimiter=',', header=None, names=['sentence', 'label'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 10000  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 16\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3z_Cwky5jCj",
        "outputId": "43819780-b511-4f25-e8e3-eb2e3fcde4c6"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 16 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mLOkH_LW9D7",
        "outputId": "2370894b-2361-401a-d046-dafd296e40e4"
      },
      "source": [
        "print(predictions)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[-3.54253769e-01,  4.70225066e-01,  1.53642565e-01,\n",
            "        -1.36005655e-01, -2.20636874e-01,  3.61267686e-01,\n",
            "         5.68789899e-01,  1.57613233e-01,  1.07246198e-01,\n",
            "         1.15503624e-01,  2.18052551e-01, -2.62194276e-01,\n",
            "         3.26330238e-03,  1.28075890e-02,  4.32719976e-01,\n",
            "         2.84763724e-01, -1.63168728e-01,  8.27834830e-02,\n",
            "         1.44616082e-01, -3.94222975e-01,  1.57037362e-01,\n",
            "         2.15125806e-03],\n",
            "       [-6.54448047e-02,  2.94807553e-01,  3.10924679e-01,\n",
            "         9.09781978e-02, -2.88607270e-01,  1.43240944e-01,\n",
            "         2.82468736e-01, -3.81513638e-03,  2.17762649e-01,\n",
            "         1.36352688e-01,  1.78145960e-01, -3.64830434e-01,\n",
            "         2.83812322e-02, -2.02735290e-01,  1.66666299e-01,\n",
            "         3.76633197e-01, -3.21721137e-01, -2.56012648e-01,\n",
            "        -5.65875731e-02, -4.81647789e-01,  1.18126415e-01,\n",
            "        -2.45382890e-01],\n",
            "       [-3.01420391e-01,  3.69282156e-01,  1.08259700e-01,\n",
            "         2.17258275e-01, -2.60439783e-01,  9.63030325e-04,\n",
            "        -6.58998117e-02,  2.21528858e-01,  1.36136757e-02,\n",
            "         1.69757903e-01, -3.40809599e-02,  1.33499295e-01,\n",
            "        -5.75607382e-02, -1.80729985e-01,  1.89162299e-01,\n",
            "         1.85853854e-01,  1.92996994e-01, -1.96529195e-01,\n",
            "        -2.69717835e-02, -2.33441114e-01,  1.00161113e-01,\n",
            "         6.71541691e-02],\n",
            "       [-2.18990415e-01,  3.45874488e-01,  5.48238494e-02,\n",
            "         9.31002796e-02, -1.94271401e-01,  1.39364049e-01,\n",
            "         3.51133913e-01,  3.47146064e-01, -3.79474849e-01,\n",
            "         1.41507402e-01,  5.87823242e-02, -3.49029273e-01,\n",
            "        -1.64720878e-01, -2.59452581e-01,  3.62405270e-01,\n",
            "         3.53683889e-01,  9.86128449e-02, -1.31483272e-01,\n",
            "        -2.55598843e-01, -3.86809498e-01,  1.91505507e-01,\n",
            "         5.87920286e-02],\n",
            "       [-2.44589806e-01,  4.34535503e-01,  1.27247840e-01,\n",
            "         2.02442855e-01, -2.30717137e-01, -3.58790793e-02,\n",
            "         1.45136878e-01,  8.16944912e-02, -5.02290279e-02,\n",
            "         3.28524381e-01,  2.18361169e-01, -2.31967732e-01,\n",
            "        -2.62452394e-01, -8.78021866e-02,  2.35622391e-01,\n",
            "         3.87697309e-01,  5.52449040e-02, -2.83450365e-01,\n",
            "        -2.30845273e-01, -3.66104037e-01,  2.85552204e-01,\n",
            "         1.36492297e-01],\n",
            "       [-3.47466826e-01,  4.58070517e-01,  1.12179518e-01,\n",
            "         8.44828412e-02, -2.82413423e-01,  1.58999130e-01,\n",
            "         3.05463254e-01,  2.91454792e-01, -8.96956474e-02,\n",
            "         4.80870783e-01,  7.58932531e-02,  8.43811780e-03,\n",
            "         1.51051218e-02, -7.19203427e-02,  2.40389933e-03,\n",
            "         2.26806387e-01,  1.45057335e-01, -1.58061981e-01,\n",
            "        -5.11469245e-02, -3.03041488e-01,  3.27841550e-01,\n",
            "         1.45638138e-01],\n",
            "       [-3.57531965e-01,  4.37274605e-01,  1.50516272e-01,\n",
            "        -1.26132920e-01,  3.11283041e-02,  3.26802075e-01,\n",
            "         3.75310242e-01,  1.84551105e-01, -1.02087282e-01,\n",
            "         1.92433164e-01, -2.73602717e-02, -2.62455702e-01,\n",
            "        -2.07939282e-01, -4.12051268e-02,  4.29113001e-01,\n",
            "         4.13517565e-01,  6.80606207e-03, -1.77160017e-02,\n",
            "        -1.10781692e-01, -2.66849786e-01,  2.04517439e-01,\n",
            "         4.27269563e-02],\n",
            "       [-2.95715481e-01,  1.82049461e-02,  1.81076363e-01,\n",
            "        -2.19158635e-01, -3.01070273e-01,  3.30911726e-01,\n",
            "         4.79584962e-01,  3.22059453e-01, -1.30937487e-01,\n",
            "         1.51171125e-02, -8.89070481e-02, -1.26647145e-01,\n",
            "        -4.06884849e-02, -9.21925232e-02,  1.82222441e-01,\n",
            "         2.36625478e-01,  7.84786269e-02, -5.11394702e-02,\n",
            "         2.20566496e-01, -5.03530502e-01,  3.35027218e-01,\n",
            "         6.47950619e-02],\n",
            "       [-1.33045241e-01,  5.37275672e-01,  1.00696780e-01,\n",
            "         1.56946972e-01, -1.19338751e-01,  6.73099905e-02,\n",
            "         2.44054303e-01,  1.35897592e-01, -2.39290092e-02,\n",
            "         4.40143973e-01,  8.57464969e-02, -1.83336094e-01,\n",
            "        -1.28870279e-01, -2.24828392e-01,  3.83859694e-01,\n",
            "         1.89360067e-01, -1.69445828e-01, -1.18946210e-01,\n",
            "        -3.60587873e-02, -2.79171616e-01,  1.06253639e-01,\n",
            "         7.94845633e-03],\n",
            "       [-2.06134453e-01,  4.04796869e-01,  2.93986857e-01,\n",
            "        -9.08386558e-02,  5.04705235e-02,  7.10195526e-02,\n",
            "         4.24376428e-01,  1.85644329e-01,  1.24948390e-01,\n",
            "         2.32608750e-01, -3.60020291e-04, -1.92904174e-01,\n",
            "        -1.20269604e-01, -6.71765432e-02,  2.80718178e-01,\n",
            "         3.37956280e-01,  7.84788579e-02, -5.50430752e-02,\n",
            "        -6.91036806e-02, -3.06328565e-01,  7.79216141e-02,\n",
            "        -9.61950347e-02],\n",
            "       [-3.67867202e-01,  5.44532478e-01,  1.29331604e-01,\n",
            "         1.18000612e-01, -2.67658025e-01,  1.14338979e-01,\n",
            "         2.93171793e-01,  1.47886574e-01,  4.98859920e-02,\n",
            "         4.82076615e-01,  1.98659942e-01, -4.24835205e-01,\n",
            "         3.08936462e-02, -1.17555052e-01,  4.01371360e-01,\n",
            "         2.41024107e-01, -5.56929447e-02, -1.72842726e-01,\n",
            "        -2.37437144e-01, -4.45815563e-01,  4.08102423e-01,\n",
            "         5.32661863e-02],\n",
            "       [-2.68256158e-01,  4.30686235e-01,  9.48009342e-02,\n",
            "         9.98190492e-02, -2.26632938e-01, -9.79221240e-02,\n",
            "         2.61888593e-01,  2.94958740e-01, -6.88147768e-02,\n",
            "         3.29004437e-01,  4.88661379e-02, -8.81806463e-02,\n",
            "        -1.34782687e-01, -2.19406188e-01,  2.59285182e-01,\n",
            "         2.62303144e-01, -7.30857775e-02, -6.48215860e-02,\n",
            "        -1.12061135e-01, -4.09546375e-01,  2.53804654e-01,\n",
            "         1.88400939e-01],\n",
            "       [-1.40786529e-01,  1.71720132e-01,  2.43455872e-01,\n",
            "         2.56471574e-01, -2.05414414e-01, -3.57687101e-02,\n",
            "         1.77454427e-01,  2.45638326e-01,  1.81425348e-01,\n",
            "         4.48594093e-01, -5.49383648e-02,  5.91969304e-03,\n",
            "        -6.38702661e-02, -8.10710266e-02,  3.23020630e-02,\n",
            "         5.31081297e-02,  2.88088292e-01, -1.78414479e-01,\n",
            "        -2.31942043e-01, -5.24397671e-01,  4.20167476e-01,\n",
            "         1.39767647e-01],\n",
            "       [-1.93966165e-01,  4.60254639e-01,  1.10762015e-01,\n",
            "         2.16500744e-01, -2.38527074e-01,  1.50224820e-01,\n",
            "         2.05016807e-01,  1.50086969e-01,  3.06500606e-02,\n",
            "         1.22273780e-01,  2.55960107e-01, -2.12812066e-01,\n",
            "        -2.17728600e-01,  5.08388784e-03,  4.21734035e-01,\n",
            "         2.11301386e-01,  1.07995391e-01, -1.24191925e-01,\n",
            "        -3.57221663e-01, -3.00380260e-01,  2.65905708e-01,\n",
            "         1.33659169e-01],\n",
            "       [-3.05243552e-01,  5.02947986e-01,  1.42973224e-02,\n",
            "         7.77792186e-02, -2.31408626e-01,  8.18002596e-02,\n",
            "         2.96944469e-01,  1.42661676e-01, -5.78233302e-02,\n",
            "         3.28121960e-01,  1.90422386e-01, -3.03183645e-01,\n",
            "        -6.25346079e-02, -9.08053666e-02,  4.64375466e-01,\n",
            "         2.48556688e-01, -1.31116107e-01, -2.64129490e-02,\n",
            "        -1.38428450e-01, -3.57844204e-01,  1.63910747e-01,\n",
            "         9.61390585e-02],\n",
            "       [-3.54482442e-01,  5.11379302e-01,  2.66769588e-01,\n",
            "        -6.86696991e-02, -1.57671541e-01,  3.49680811e-01,\n",
            "         5.13642907e-01,  1.69238135e-01,  7.54348794e-03,\n",
            "         4.33436573e-01,  8.94916728e-02, -4.30287570e-01,\n",
            "         2.06948631e-02, -4.85093966e-02,  3.79531682e-01,\n",
            "         3.77987117e-01, -7.26134256e-02, -1.82018802e-01,\n",
            "        -9.33279023e-02, -4.08430576e-01,  2.95424044e-01,\n",
            "        -3.53299491e-02]], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Bl3Q8sXVqO",
        "outputId": "8b4a1e28-f728-4f83-e2fc-d0730c104f64"
      },
      "source": [
        "print(true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([12, 13, 14, 10, 15, 16, 17, 18, 19,  5,  5,  2,  2,  3,  3,  3])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgZgEFb38FKN"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDLaK5HJ8JHM"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxuYdygj8bg1"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}